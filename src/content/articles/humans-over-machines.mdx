---
layout: ../../layouts/ArticleLayout.astro
title: Humans over machines
summary: Entrusting AI with the future of society while giving up the pursuit of excellence, expertise and human growth is a mistake with lasting negative consequences. AI should not be seen as the next stage of human society, for it is just a tool that relies on human generated knowledge to be 'intelligent'.
createdAt: 2025-04-21
updatedAt: 2025-06-13
topics:
  - AI
  - Human excellence
isDraft: false
---

In times when seemingly all companies believe that AI is the solution to all their problems, that it will enable the reduction of the human capital and increase revenue, I believe we should all meditate on the truthiness of these promises, their repercusions, and what's truly best for mankind in the grand scheme of things.

## The good and the bad

AI is indubitable one of the most relevant technological inventions of the century. The applications of AI are numerous and there are real world examples that show of much good it can do for mankind:

- improving patient care;
- optimizing processes in hospitals;
- improving elderly care;
- predicting the likelihood of Alzheimer's disease, etc.

Unfortunately, the number of bad applications of AI by far surpass the good ones. Here are a few ([source](https://builtin.com/artificial-intelligence/risks-of-artificial-intelligence)):

- automation-spurred job loss;
- deepfakes;
- privacy violations;
- algorithmic bias caused by bad data;
- socioeconomic inequality;
- market volatility;
- weapons automatisation;
- uncontrollable self-aware AI.

The last one might sound like an exaggeration, but you should know that Geoffrey Hinton, also known as the **the Godfather of AI**, has been an active voice warning the world about the danger that unrestricted pursuit and application of AI will have on mankind. In 2024, in his joint Nobel Prize in Physics acceptance speech, Geoffrey said:

> [...] Unfortunately, the rapid progress in AI comes with many short-term risks. It has already created divisive echo-chambers by offering people content that makes them indignant. It is already being used by authoritarian governments for massive surveillance and by cyber criminals for phishing attacks. In the near future AI may be used to create terrible new viruses and horrendous lethal weapons that decide by themselves who to kill or maim. All of these short-term risks require urgent and forceful attention from governments and international organizations.
>
> There is also a longer term existential threat that will arise when we create digital beings that are more intelligent than ourselves. We have no idea whether we can stay in control. But we now have evidence that if they are created by companies motivated by short-term profits, our safety will not be the top priority. We urgently need research on how to prevent these new beings from wanting to take control. They are no longer science fiction.
>
> -- Geoffrey Hinton, 2024

[Geoffrey Hinton's full speech](https://www.nobelprize.org/prizes/physics/2024/hinton/speech/)

If one of the most influential individuals in the creation of AI had this to say about AI, who are we, mere users, to assume we know better?

## AI hype: who stands to gain

I have no doubt that the hype surrounding AI is a by-product not only of its capabilities but, mainly, by those who wish to profit from it regardless of the consequences.

All major companies are competiting with one another for the supremacy in this not-so-newfound gold mine. They are aware of the massive gains AI can bring, and they are doing everything to convince both organizations and governments to give them their money.

Cybercriminals are having a wonderful time swindling gullible people, robbing artists of their intellectual properties, robbing identities, etc.

Companies hell-bent on cutting operational costs and increasing revenue while also fulfilling their desire to seem relevant (basically FOMO at an origanization level) because "every other company" is also integrating AI in their processes, have started massive layoff rounds and imposing the use of AI in their software development departments in hopes that, in the near future, it replaces the majority of their development teams. Look it up, it shouldn't be too hard to find Google's and Facebook's **proud** announcements of this practice.

None of the examples above produce outcomes that benefit the average human being. It's the opposite: life, which is hard in itself without these devious shenanigans from money-hungry corporations, becomes much harder!

## Human mediocrity as a by-product of unfiltered AI usage

We get to benefit from all innovations that exist **today** because those who came **before** us strived for greatness in their fields. Building upon past efforts to gain a deeper and better understanding of a subject is one of the most valuable human skills but, unfortunately, with the advent of AI, almost (so it would seem) everyone has given up on becoming excellent. No one differentiates dumb tasks from critical ones, whether at work on school, mindlessly trusting the results provided by suspicious AIs (suspicions because they are free, provided by money-hungry corporations), taking them at face value while, at the same time, letting go of the opportunity to put their brains to work and expand their cognitive capabilities.

I do use AI, but only for **dumb** tasks, those that require little to no thinking. Why? I am glad you asked:

- because if I rely on AI to do task that require mental effort I will stop learning and growing;
- because the AI agents at our disposal are error prone;
- because there's no clarity on what is made out of our inputs, and;
- most importantly, because aiming for excellence, greatness even, is what humans should aim for; it is the only way make the world a better place and leave a valuable legacy for future generations.

## Conclusion

I'm writing the conclusion having barely scratched the surface of this very complex, widespread but poorly understood phenomenon and technological innovation. I hope this article makes you think thoroughly about AI, pessimistically if possible, for the future will be dystopian if we don't stop to collectively define how may it be used without putting mankind in harm's way.

